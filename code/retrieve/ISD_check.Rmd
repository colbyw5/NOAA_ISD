---
title: "NOAA ISD Data Curation"
author: "Colby Wilkinson"
date: "10/31/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(data.table)
library(threadr)
```

Setting up collection: reading in the ISD stations for which we need data, and the beginning/ending years of data collection

```{r}

isd_stations_data <- read_csv("../../data/locations/ISD Stations.csv") %>% 
  distinct(ISD_station, BEGIN, END) %>% 
  mutate(BEGIN = str_sub(BEGIN, start = 1, end = 4),
         END = str_sub(END, start = 1, end = 4))
```

Creating a directory for temporary data storage during collection, a vector of ISD stations, and a list to hold resulting data files

```{r}
ISD_stations <- isd_stations_data$ISD_station

isd_data_list <- list()

```


The function below downloads the ISD data file for the station/year combination and replace missing value indicators (-9999/9999) with NA

```{r}
getISD <- function(year, station, directory, save_file = FALSE){
  
  isd_data <- tryCatch(
  
  {
    # downloading data
  
  url <- paste("ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-lite/", year, "/", station, "-", year, ".gz", sep = "")
  
  download_ftp_file(file_remote = url,
                  file_local = paste(directory, station, "-", year, ".gz", sep = ""),
                  credentials = "anonymous:noaa")
  
  # creating dataset
  
  isd_data <- read_table(gzfile(paste(directory, station, "-", year, ".gz", sep = "")),
                           col_names = c("year", "month", "day", "hour", "temp", "dew", "press", "wind_dir", "wind_speed", "sky", "prec_1", "prec_6")) %>% 
    mutate(station = station,
           temp = ifelse(temp == -9999 | temp == 9999, NA, temp),
           dew = ifelse(dew == -9999 | dew == 9999, NA, dew),
           press = ifelse(press == -9999 | press == 9999, NA, press),
           wind_speed = ifelse(wind_speed == -9999 | wind_speed == 9999, NA, wind_speed),
           prec_1 = ifelse(prec_1 == -9999 | prec_1 == 9999, NA, prec_1),
           prec_6 = ifelse(prec_6 == -9999 | prec_6 == 9999, NA, prec_6),
           temp = ((temp/10)*(9/5))+32,
           dew = ((dew/10)*(9/5))+32,
           press = press/10,
           wind_speed = wind_speed/10,
           prec_1 = prec_1/10,
           prec_6 = prec_6/10,
           prec_1 = ifelse(prec_1 == -0.1, 0.01, prec_1)) %>% 
    select(-c(sky, wind_dir, prec_6))
  
  # removing NA indicators
  
  isd_data[isd_data == -9999 | isd_data == 9999] = NA
  
  # saving/deleting data file
  
  if (save_file){
    # do not delete file
  }else{
    unlink(paste(directory, "/*", sep = ""))
  }
  
  # close file connections
  closeAllConnections()
  
  return(isd_data)
  
  },
  error = function(cond){
    
    message(cond)
    
    return(NA)
    
  }
  )
  
  return(isd_data)
}

```

Below we look over the stations for which we need data, and add the resulting data to the initialized list

```{r, error=FALSE, message=FALSE, warning=FALSE}
for (station in ISD_stations){
  
  # finding beginning/end of station collection
  
  begin <- max(isd_stations_data$BEGIN[isd_stations_data$ISD_station == station], 1989)
  
  end <- isd_stations_data$END[isd_stations_data$ISD_station == station]
  
  for (year in begin:end){
    
    isd_data_list[[paste(station, year, sep = "-")]] <- getISD(year = year, station = station, directory = "../../data/raw/")
    
  }
  
}
```

Binding the resulting datasets together, saving to a csv file

```{r}
rbindlist(isd_data_list[!is.na(isd_data_list)]) %>% 
  filter(year == 2018 & month == "07" & day %in% c("24", "25")) %>% 
  view()

```

```{r}
read_csv("../../data/locations/ISD Stations.csv") %>% 
  mutate(az_dist = sqrt((LAT - 32.65)^2 + (LON - -111.59)^2)) %>% 
  filter(az_dist < .7) %>% 
  select(-az_dist) %>% 
  view()
```

11/3/2019: Updating ISD station for all locations

```{r}
isd_stations_data <- read_csv("../../data/locations/ISD Stations.csv") %>% 
  distinct(ISD_station, BEGIN, END) %>% 
  mutate(BEGIN = str_sub(BEGIN, start = 1, end = 4),
         END = str_sub(END, start = 1, end = 4))
```

Loading locaitons, filtering out major cities for which we have already assinged stations manually

```{r}

```


Current Locations

```{r}
locations <- read_csv("./data/locations.csv") %>% 
  filter()
```

Matching stations to locations by distance

dlon = lon2 - lon1 
dlat = lat2 - lat1 
a = (sin(dlat/2))^2 + cos(lat1) * cos(lat2) * (sin(dlon/2))^2 
c = 2 * atan2( sqrt(a), sqrt(1-a) ) 
d = R * c (where R is the radius of the Earth)


```{r}
distance <- function(lat1, lon1, lat2, lon2, R = 3961){
  
  # convert degrees to radians
  
  lat1 = lat1 * (pi/180)
  lon1 = lon1 * (pi/180)
  lat2 = lat2 * (pi/180)
  lon2 = lon2 * (pi/180)
  
  a = (sin((lat2 - lat1)/2))^2 + cos(lat1) * cos(lat2) * (sin((lon2 - lon1)/2))^2
  b = 2 * atan2(sqrt(a), sqrt(1-a))

  return(R * b)
}

```


```{r}
locations %>% 
 left_join(stations %>%
              rename(state = station_state), by = "state") %>% 
  mutate(lat_lon_dist = sqrt((LON-location_lon)^2+(LAT-location_lat)^2),
         zip_match = zip_code == station_zip_code,
         full_range = (as.numeric(str_sub(END, start = 1, end = 4)) == 2019 & as.numeric(str_sub(BEGIN, start = 1, end = 4)) < 1994)) %>% 
  group_by(location_code) %>% 
  mutate(min_dist = lat_lon_dist == min(lat_lon_dist, na.rm = TRUE)) %>% 
  ungroup() %>% 
  filter(lat_lon_dist < 0.5) %>% 
  write_csv("./data/locations ISD.csv")

```
